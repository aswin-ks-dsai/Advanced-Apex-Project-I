# Clustering Biological Specimens by Morphological Features

End-to-end unsupervised learning pipeline for clustering Dry Bean biological specimens using morphological shape and size features. Includes full workflow: data extraction, preprocessing, feature engineering, optimal-k selection (Elbow + Silhouette), K-Means training, inference on production data, and internal evaluation.

---

## ğŸ“Œ Project Overview

This project applies **unsupervised clustering (K-Means)** to group Dry Bean samples based on their geometric and morphological characteristics.  The goal is to automatically discover natural structure among bean types and support research, automated classification, and agricultural decision-making.

---

## ğŸ¯ Problem Statement / Business Goal

Traditional dry bean identification depends on slow, subjective manual inspection.  
This project builds an **automated clustering system** that groups beans purely from shape-related featuresâ€”enabling:

- Faster and scalable bean categorization  
- Objective and consistent grouping  
- Better support for agricultural research and quality control  

---

## ğŸ“‚ Dataset Source & Citation

**Dataset:** Dry Bean Dataset  
**Source:** UCI Machine Learning Repository  
ğŸ”— https://archive.ics.uci.edu/dataset/602/dry+bean+dataset  

**Citation:**  
Seker, Barbunya, Bombay, Cali, Dermosan, Horoz, and Sira â€” Dry Bean Dataset.  
UCI Machine Learning Repository (CC BY 4.0).

---
## ğŸ“ Repository Structure (The structure and files formed after executing the entire notebook)

```txt
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Bean_Data_Full.csv
â”‚   â”œâ”€â”€ Bean_Data_75pct.csv
â”‚   â”œâ”€â”€ Bean_Data_25pct_Eval_Inf.csv
â”‚   â”œâ”€â”€ predictions.csv
â”‚   â”œâ”€â”€ result_summary.csv
|
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ selected_features.pkl
â”‚   â”œâ”€â”€ kmeans_model.pkl
â”‚
â”œâ”€â”€ Vector_Minds_Phase_1_and_4.ipynb
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ training_clusters.png
â”‚   â”œâ”€â”€ production_clusters.png
â”‚   â”œâ”€â”€ training_vs_production_clusters.png
```
---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Open the Notebook
Use the main notebook:

`Vector_Minds_Phase_1_and_4.ipynb`

You may run it in:

- Google Colab (recommended)  
- Jupyter Notebook / VS Code  

---

### 2ï¸âƒ£ Install Required Libraries

Upload or Copy the requirements.txt to your  project folder and run the pip install cell in the notebook
```
pip install -r requirements.txt
```



---

### 3ï¸âƒ£ Run All Cells

Running the notebook will:

- Fetch the dataset (via `ucimlrepo`)
- Clean & preprocess the data  
- Apply PowerTransformer + StandardScaler  
- Reduce correlated features  
- Identify optimal k using Elbow + Silhouette  
- Train **K-Means (k = 7)**  
- Run inference on production dataset  
- Generate analysis plots  
- Save artifacts for reuse  

---

## ğŸ“Š Outputs Generated

### **âœ” Visualizations**
- Training cluster scatter plot  
- Production cluster scatter plot  
- Training vs inference comparison  
- Correlation heatmap  
- Distribution & skew plots  

---

### **âœ” Model Artifacts**
- `selected_features.pkl`  
- `kmeans_model.pkl`  

---

### **âœ” Evaluation Metrics**
- Silhouette Score  
- Daviesâ€“Bouldin Index (Training & Inference)  
- Optional internal evaluation:
  - ARI / AMI  
  - Confusion Matrix  
  - Cluster Purity  

---
